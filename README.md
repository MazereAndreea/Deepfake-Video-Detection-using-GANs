
# Deepfake Video Detection using GANs

This project aims to implement a Generative Adversarial Network (GAN) to detect deepfake images in videos. The project leverages deep learning models using PyTorch and utilizes the CelebA dataset for training. The generator creates realistic images from random noise, and the discriminator differentiates between real and fake images.




## Table of contents

- [Overview](#overview)
- [Tech stack](#technologies)
- [Training](#training)
- [Results](#results)
- [Steps for pulling the docker image](#docker)

## Overview

The project involves using a GAN, where the generator and discriminator are both trained on the CelebA dataset to generate and detect fake images. The model is trained using the following steps:

&nbsp;&nbsp;1. **Generator**: 
   Takes random noise as input and generates synthetic images that resemble real data.
  
&nbsp;&nbsp;2. **Discriminator**: 
   Classifies images as either real (from the dataset) or fake (generated by the generator).
  
&nbsp;&nbsp;3. **Training**:
   The generator and discriminator are trained in opposition, continuously improving through each iteration. 
   The generator tries to produce more realistic images, while the discriminator works to better differentiate between real and fake images.

&nbsp;&nbsp;3. **Validation**:
   The discriminator is evaluated on a batch of the same size as for training depending on the losses calculated at each iteration. The same dataset is used, but
   only the reserved images for validation.

&nbsp;&nbsp;3. **Testing**:
   The discriminator is tested on a different dataset, CelebDF, which consists of videos of celebrities, real and fake gathered from youtube. 

The modelâ€™s performance is evaluated based on the discriminator's ability to distinguish fake images generated by the generator. Training progress and results are logged to **TensorBoard**, allowing for real-time visualization of losses and generated image samples.

## Tech Stack

**Frameworks and Libraries:** PyTorch, TensorFlow, Torchvision

**Modeling:** Generative Adversarial Networks (GANs), Convolutional Neural Networks (CNNs)

**Data Handling:** CelebA dataset Celeb DF, PyTorch DataLoader

**Training & Evaluation:** CUDA, TensorBoard, Adam optimizer, BCELoss


## Training
Training involves running the main.py script. The generator and discriminator will be trained using the CelebA dataset. Training logs and visualizations will be saved in the runs/generative_model directory, which can be viewed using TensorBoard.

To start TensorBoard:

```bash
  tensorboard --logdir=runs
```

## Results
Using these hyperparameters:
**Batch**: 128;
**Epoch**: 10;
**noise for latent vector** = 100;
**learning rate** = 0.0002 for both networks;

![imageData_10epochs](https://github.com/user-attachments/assets/cbc28e28-e1ef-4c9e-a8cf-4068f899654a)

**Batch**: 128;
**Epoch**: 20;
**noise for latent vector** = 100;
**learning rate discriminator** = 0.0002;
**learning rate generator** = 0.0005;

![image](https://github.com/user-attachments/assets/4cb44110-e59c-4859-9cf7-7cc47ad44fd4)

**Batch**: 128;
**Epoch**: 30;
**noise for latent vector** = 100;
**learning rate discriminator** = 0.0002;
**learning rate generator** = 0.001;

![image](https://github.com/user-attachments/assets/af43d7ac-73fb-4fcf-b82f-0b65ce35bc3c)



## Steps for pulling the docker image
Make sure you have docker installed on you machine before completing these steps.
Start docker and open cmd and enter these commands:
```bash
  docker login
```
```bash
  docker pull andreeamaz/deepfakedetection
```
*This line is optional, if you want to see that the image was pulled correctly:
```bash
  docker images
```
Make sure port 5000 is available on your local machine before running this step:
```bash
  docker run -d -p 5000:5000 andreeamaz/deepfakedetection
```
*This line is optional, if you want to see running containers:
```bash
  docker ps
```
After running these commands, the app will be available at http://localhost:5000/ on your local machine




